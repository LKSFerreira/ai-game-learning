"""
Mﾃｳdulo: ｧｪ test_agente.py
Projeto: 祷 AI Game Learning

Este arquivo contﾃｩm testes para a classe AgenteQLearning, verificando
se o "cﾃｩrebro" da nossa IA funciona como esperado.

Para executar, use o comando no terminal:
python fase-2_jogo_velha/test_agente.py
"""

from agente import AgenteQLearning

def testar_inicializacao():
    """Verifica se o Agente ﾃｩ criado com os atributos corretos."""
    print("--- INICIANDO TESTE 1: INICIALIZAﾃﾃグ DO AGENTE ---")
    agente = AgenteQLearning(jogador=2)
    
    assert agente.jogador == 2
    assert agente.simbolo == 'O'
    assert agente.alpha == 0.5
    assert len(agente.tabela_q) == 0
    
    print("笨 Agente criado com sucesso como jogador 'O'.")
    print("--- TESTE 1 FINALIZADO ---\n")

def testar_atualizacao_q_valor():
    """Testa se a Equaﾃｧﾃ｣o de Bellman estﾃ｡ sendo aplicada corretamente."""
    print("--- INICIANDO TESTE 2: APRENDIZADO (ATUALIZAﾃﾃグ DE Q-VALOR) ---")
    agente = AgenteQLearning(alpha=0.5, gamma=0.9)
    
    estado_inicial = (0, 0, 0, 0, 0, 0, 0, 0, 0)
    acao = 4 # Jogar no centro
    proximo_estado = (0, 0, 0, 0, 1, 0, 0, 0, 0)
    recompensa = 0.0
    
    # Simula que a melhor jogada futura vale 0.8
    agente.tabela_q[proximo_estado] = {0: 0.5, 1: 0.8, 2: 0.3}
    
    valor_antigo = agente.obter_valor_q(estado_inicial, acao)
    print(f"Opiniﾃ｣o antiga sobre jogar no centro: {valor_antigo}")
    
    agente.atualizar_valor_q(estado_inicial, acao, recompensa, proximo_estado)
    
    valor_novo = agente.obter_valor_q(estado_inicial, acao)
    # Cﾃ｡lculo esperado: 0 + 0.5 * (0 + 0.9 * 0.8 - 0) = 0.36
    print(f"Nova opiniﾃ｣o sobre jogar no centro: {valor_novo:.2f}")
    assert round(valor_novo, 2) == 0.36
    
    print("笨 O Agente ajustou sua estratﾃｩgia corretamente!")
    print("--- TESTE 2 FINALIZADO ---\n")

def testar_escolha_de_acao():
    """Verifica se a estratﾃｩgia Epsilon-Greedy funciona."""
    print("--- INICIANDO TESTE 3: ESCOLHA DE Aﾃﾃグ (EPSILON-GREEDY) ---")
    estado = (1, 2, 0, 0, 0, 0, 0, 0, 0)
    acoes_validas = [2, 3, 4, 5, 6, 7, 8]
    
    # Cenﾃ｡rio 1: Agente Aventureiro (epsilon alto)
    agente_aventureiro = AgenteQLearning(epsilon=1.0) # 100% de chance de explorar
    acao_escolhida = agente_aventureiro.escolher_acao(estado, acoes_validas)
    print(f"Agente Aventureiro (ﾎｵ=1.0) escolheu a aﾃｧﾃ｣o: {acao_escolhida}")
    assert acao_escolhida in acoes_validas

    # Cenﾃ｡rio 2: Agente Estrategista (epsilon baixo)
    agente_estrategista = AgenteQLearning(epsilon=0.0) # 0% de chance de explorar
    agente_estrategista.tabela_q[estado] = {2: 0.5, 3: 0.1, 4: 0.9} # Aﾃｧﾃ｣o 4 ﾃｩ a melhor
    acao_escolhida = agente_estrategista.escolher_acao(estado, acoes_validas)
    print(f"Agente Estrategista (ﾎｵ=0.0) escolheu a aﾃｧﾃ｣o: {acao_escolhida}")
    assert acao_escolhida == 4
    
    print("笨 O Agente estﾃ｡ balanceando exploraﾃｧﾃ｣o e estratﾃｩgia como esperado.")
    print("--- TESTE 3 FINALIZADO ---\n")

def executar_todos_testes():
    """Funﾃｧﾃ｣o principal para rodar toda a suﾃｭte de testes."""
    print("\n" + "="*50)
    print("ｧｪ INICIANDO BATERIA DE TESTES DO AGENTE ｧｪ")
    print("="*50 + "\n")
    
    testar_inicializacao()
    testar_atualizacao_q_valor()
    testar_escolha_de_acao()
    
    print("="*50)
    print("笨 TODOS OS TESTES DO AGENTE CONCLUﾃ好OS COM SUCESSO!")
    print("="*50 + "\n")

if __name__ == "__main__":
    executar_todos_testes()